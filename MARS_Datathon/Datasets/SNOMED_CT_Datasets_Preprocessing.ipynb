{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lBCxoaoIw53O"},"outputs":[],"source":["from google.colab import drive\n","\n","# 구글 드라이브 마운트\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"isXsOLZ50796"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","SNOMED CT RF2(Snapshot_INT_YYYYMMDD) -> (개념-설명) 쌍 생성 -> Qwen3-8B SFT JSONL\n","- 파일 자동 탐색(같은 배포 날짜 우선)\n","- 활성(active==1)만 사용\n","- 언어 refset 기반 Preferred term 우선 선택\n","- TextDefinition 있으면 설명으로 사용, 없으면 짧은 기본 문장으로 대체\n","- synonyms를 meta로 함께 저장(선택)\n","\"\"\"\n","\n","from pathlib import Path\n","import pandas as pd\n","import re, json\n","\n","# ==================== 사용자 설정 ====================\n","BASE = Path(\"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/SNOMED_CT_datasets/SNOMED_International/SnomedCT_InternationalRF2/Snapshot\")\n","OUT_JSONL = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/SNOMED_CT_datasets/snomed_concept_description_qwen.jsonl\"\n","\n","# 선호 언어 Refset ID (US English=900000000000509007, GB English=900000000000508004)\n","# 한국어 refset을 쓸 경우 여기를 해당 refsetId로 교체하세요.\n","REFSET_LANG_ID = 900000000000509007  # US English\n","# ====================================================\n","\n","def pick_first(paths):\n","    paths = list(paths)\n","    return paths[0] if paths else None\n","\n","def find_release_files(base: Path):\n","    # Concept\n","    concept_fp = pick_first(base.rglob(\"Terminology/sct2_Concept_Snapshot_INT_*.txt\")) \\\n","              or pick_first(base.rglob(\"**/sct2_Concept_Snapshot_INT_*.txt\"))\n","    if not concept_fp:\n","        raise FileNotFoundError(\"Concept Snapshot 파일을 찾지 못했습니다.\")\n","    print(\"[Concept]\", concept_fp)\n","\n","    m = re.search(r\"_(\\d{8})\\.txt$\", concept_fp.name)\n","    if not m:\n","        raise RuntimeError(\"Concept 파일명에서 날짜(YYYYMMDD)를 추출하지 못했습니다.\")\n","    date_str = m.group(1)\n","    print(\"[DATE]\", date_str)\n","\n","    # Description (동일 날짜 우선)\n","    desc_fp = pick_first(base.rglob(f\"Terminology/sct2_Description_Snapshot-en_INT_{date_str}.txt\")) \\\n","           or pick_first(base.rglob(f\"**/sct2_Description_Snapshot-en_INT_{date_str}.txt\")) \\\n","           or pick_first(base.rglob(\"**/sct2_Description_Snapshot-en_INT_*.txt\"))\n","    if not desc_fp:\n","        raise FileNotFoundError(\"Description Snapshot 파일을 찾지 못했습니다.\")\n","    print(\"[Description]\", desc_fp)\n","\n","    # TextDefinition (선택)\n","    textdef_fp = pick_first(base.rglob(f\"Terminology/sct2_TextDefinition_Snapshot-en_INT_{date_str}.txt\")) \\\n","              or pick_first(base.rglob(f\"**/sct2_TextDefinition_Snapshot-en_INT_{date_str}.txt\")) \\\n","              or pick_first(base.rglob(\"**/sct2_TextDefinition_Snapshot-en_INT_*.txt\"))\n","    print(\"[TextDefinition]\", textdef_fp if textdef_fp else \"없음\")\n","\n","    # Language refset (여러 개일 수 있어 패턴 넓게)\n","    lang_candidates = []\n","    for pat in [\n","        f\"Refset/Language/der2_cRefset_Language*{date_str}.txt\",\n","        f\"**/der2_cRefset_Language*{date_str}.txt\",\n","        \"Refset/Language/der2_cRefset_Language*.txt\",\n","        \"**/der2_cRefset_Language*.txt\",\n","    ]:\n","        lang_candidates += list(base.rglob(pat))\n","    lang_candidates = sorted(set(lang_candidates), key=lambda p: p.name)\n","    if not lang_candidates:\n","        raise FileNotFoundError(\"Language refset 파일을 찾지 못했습니다.\")\n","    # 실제로는 여러 언어 파일이 존재할 수 있음. 여기서는 '선호 refset id'로 필터링할 것이므로 아무거나 하나 잡아 로딩 후 필터링.\n","    lang_fp = lang_candidates[0]\n","    print(\"[Language(any)]\", lang_fp.parent)\n","\n","    return concept_fp, desc_fp, textdef_fp, lang_fp\n","\n","def strip_semantic_tag(t: str) -> str:\n","    # \"Neoplasm of jejunum (disorder)\" -> \"Neoplasm of jejunum\"\n","    m = re.match(r\"^(.*)\\s\\([^)]+\\)$\", t)\n","    return m.group(1) if m else t\n","\n","def main():\n","    concept_fp, desc_fp, textdef_fp, lang_fp = find_release_files(BASE)\n","\n","    # === 로드 (dtype 최적화) ===\n","    dtype_common = {\"id\":\"string\",\"effectiveTime\":\"string\",\"active\":\"int8\",\"moduleId\":\"string\"}\n","\n","    print(\"Loading Concepts...\")\n","    # Concepts: conceptId는 숫자라 유지 가능\n","    concepts = pd.read_csv(concept_fp, sep=\"\\t\",\n","        dtype={**dtype_common, \"definitionStatusId\":\"string\"}  # <- string로 통일해도 무방\n","    )\n","    # 나중에 쓸 열만 int로 바꾸기\n","    concepts[\"id\"] = concepts[\"id\"].astype(\"int64\")  # conceptId는 숫자 보장\n","    concepts = concepts.query(\"active==1\")[[\"id\"]].rename(columns={\"id\":\"conceptId\"})\n","\n","    # Descriptions: description의 id는 문자열(조인 키), conceptId는 숫자\n","    descs = pd.read_csv(desc_fp, sep=\"\\t\",\n","        dtype={**dtype_common,\n","               \"conceptId\":\"int64\",\n","              \"languageCode\":\"string\",\n","              \"typeId\":\"string\",              # 안전하게 문자열\n","              \"term\":\"string\",\n","              \"caseSignificanceId\":\"string\"}\n","    ).query(\"active==1\")\n","\n","    # Language refset: 전부 문자열로(특히 id / referencedComponentId / acceptabilityId)\n","    lang_all = pd.read_csv(lang_fp, sep=\"\\t\",\n","        dtype={**dtype_common,\n","               \"refsetId\":\"string\",\n","              \"referencedComponentId\":\"string\",\n","              \"acceptabilityId\":\"string\"}\n","    ).query(\"active==1\")\n","\n","    if textdef_fp:\n","        textdefs = pd.read_csv(textdef_fp, sep=\"\\t\",\n","            dtype={**dtype_common,\n","                  \"conceptId\":\"int64\",\n","                  \"languageCode\":\"string\",\n","                  \"typeId\":\"string\",\n","                  \"term\":\"string\",\n","                   \"caseSignificanceId\":\"string\"}\n","        ).query(\"active==1\")\n","    else:\n","        textdefs = pd.DataFrame(columns=[\"conceptId\",\"term\"]).assign(typeId=[])\n","\n","    # === 상수: 문자열로 통일 ===\n","    TYPEID_FSN       = \"900000000000003001\"\n","    TYPEID_SYNONYM   = \"900000000000013009\"\n","    TYPEID_TEXT_DEF  = \"900000000000550004\"\n","\n","    ACC_PREFERRED    = \"900000000000548007\"\n","    ACC_ACCEPTABLE   = \"900000000000549004\"\n","\n","    REFSET_LANG_ID   = \"900000000000509007\"  # 이미 문자열\n","\n","    # === 활성 필터 ===\n","    #concepts = concepts.query(\"active==1\")[[\"id\"]].rename(columns={\"id\":\"conceptId\"})\n","    descs = descs.query(\"active==1\")\n","    textdefs = textdefs.query(\"active==1\") if not textdefs.empty else textdefs\n","\n","    # 선택한 언어 refset만 사용\n","    lang = lang_all.query(\"refsetId==@REFSET_LANG_ID\")[\n","        [\"referencedComponentId\",\"acceptabilityId\"]\n","    ].rename(columns={\"referencedComponentId\":\"descriptionId\"})\n","\n","    if lang.empty:\n","        print(f\"[WARN] 선택한 REFSET_LANG_ID={REFSET_LANG_ID} 에 해당하는 레코드가 없습니다.\")\n","        print(\"       der2_cRefset_Language*.txt 내 refsetId 분포를 확인해 올바른 refsetId로 교체하세요.\")\n","        # 계속 진행은 가능하지만, acceptability 기반 선택이 제한됨.\n","\n","    # === 설명(라벨) 선택 로직 ===\n","    # Synonym 중 Language refset의 Preferred를 최우선\n","    syn = descs.query(\"typeId==@TYPEID_SYNONYM\")[[\"id\",\"conceptId\",\"term\"]].rename(columns={\"id\":\"descriptionId\"})\n","    # 언어 refset 조인 (없으면 NaN)\n","    syn = syn.merge(lang, on=\"descriptionId\", how=\"left\")\n","    syn[\"acc_score\"] = syn[\"acceptabilityId\"].map({ACC_PREFERRED:2, ACC_ACCEPTABLE:1}).fillna(0).astype(int)\n","    syn_ranked = syn.sort_values([\"conceptId\",\"acc_score\"], ascending=[True, False])\n","    preferred_syn = syn_ranked.groupby(\"conceptId\", as_index=False).first()[[\"conceptId\",\"term\",\"acc_score\"]]\n","    preferred_syn = preferred_syn.rename(columns={\"term\":\"label\"})\n","\n","    # FSN fallback\n","    fsn = descs.query(\"typeId==@TYPEID_FSN\")[[\"conceptId\",\"term\"]].rename(columns={\"term\":\"fsn\"})\n","    fsn[\"fsn_clean\"] = fsn[\"fsn\"].map(strip_semantic_tag)\n","\n","    label_df = concepts.merge(preferred_syn, on=\"conceptId\", how=\"left\") \\\n","                       .merge(fsn[[\"conceptId\",\"fsn_clean\"]], on=\"conceptId\", how=\"left\")\n","    # label = Preferred synonym or FSN(clean)\n","    label_df[\"label\"] = label_df[\"label\"].fillna(label_df[\"fsn_clean\"])\n","    label_df = label_df.drop(columns=[c for c in [\"acc_score\",\"fsn_clean\"] if c in label_df.columns])\n","\n","    # 정의문(있으면 붙이기)\n","    if not textdefs.empty:\n","        defs = textdefs.query(\"typeId==@TYPEID_TEXT_DEF\")[[\"conceptId\",\"term\"]] \\\n","                       .rename(columns={\"term\":\"definition\"})\n","    else:\n","        defs = pd.DataFrame(columns=[\"conceptId\",\"definition\"])\n","\n","    pairs = label_df.merge(defs, on=\"conceptId\", how=\"left\")\n","\n","    # (라벨/FSN 만들고 나서) 동의어 목록 만들기 바로 전에 교체\n","    syn[\"term\"] = syn[\"term\"].astype(\"string\").str.strip()          # 문자열+공백 제거\n","    syn_valid = syn[syn[\"term\"].notna() & (syn[\"term\"] != \"\")]      # NA/빈문자 제거\n","\n","    # 순서 보존 dedup\n","    syn_list = (\n","       syn_valid.groupby(\"conceptId\")[\"term\"]\n","        .agg(lambda col: list(dict.fromkeys(col.tolist())))\n","       .reset_index(name=\"synonyms\")\n","    )\n","\n","    pairs = pairs.merge(syn_list, on=\"conceptId\", how=\"left\")\n","    pairs[\"synonyms\"] = pairs[\"synonyms\"].apply(lambda x: x if isinstance(x, list) else [])\n","\n","    # 후처리\n","    pairs[\"label\"] = pairs[\"label\"].fillna(\"\").astype(str).str.strip()\n","    pairs[\"definition\"] = pairs[\"definition\"].fillna(\"\").astype(str).str.strip()\n","    pairs[\"synonyms\"] = pairs[\"synonyms\"].apply(lambda x: x if isinstance(x, list) else [])\n","\n","    # 빈 라벨 제거(이상치)\n","    pairs = pairs[pairs[\"label\"] != \"\"].copy()\n","\n","    print(\"Total active concepts kept:\", len(pairs))\n","\n","    # === Qwen3-8B용 JSONL로 저장 ===\n","    # messages: user=label, assistant=definition(or fallback)\n","    # meta: conceptId, synonyms\n","    n_written = 0\n","    with open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n","        for _, r in pairs.iterrows():\n","            concept = r[\"label\"]\n","            desc = r[\"definition\"] if r[\"definition\"] else f\"{concept}에 대한 의학 개념입니다.\"\n","            rec = {\n","                \"messages\": [\n","                    {\"role\":\"user\", \"content\": concept},\n","                    {\"role\":\"assistant\", \"content\": desc}\n","                ],\n","                \"meta\": {\n","                    \"conceptId\": int(r[\"conceptId\"]),\n","                    \"synonyms\": r[\"synonyms\"]\n","                }\n","            }\n","            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n","            n_written += 1\n","\n","    print(f\"Saved JSONL: {OUT_JSONL} (rows={n_written})\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oQ64kp2388tA"},"outputs":[],"source":["jsonl_path = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/SNOMED_CT_datasets/snomed_concept_description_qwen.jsonl\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtfVa57W3FN1"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_json(jsonl_path, lines=True)\n","\n","# 완전 텍스트 출력\n","print(df.head(10).to_string(index=False))\n"]},{"cell_type":"markdown","metadata":{"id":"W7joBFE-Ttyj"},"source":["# term-definition쌍으로 된 JSONL생성 코드(conceptId/동의어 제외)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BeGULCPtUVOY"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","SNOMED CT RF2 (Snapshot_INT_YYYYMMDD) -> (term, definition) JSONL for SFT\n","- conceptId / synonyms 제외\n","- 활성(active==1)만 사용\n","- 언어 refset 기반 Preferred term 우선 선택 (US English 기본)\n","- TextDefinition 있으면 정의로 사용\n","- 없으면 결측 처리 정책(MISSING_DEFINITION_POLICY) 적용: 'drop' 또는 'fallback'\n","\"\"\"\n","\n","from pathlib import Path\n","import pandas as pd\n","import re, json\n","\n","# ==================== 사용자 설정 ====================\n","BASE = Path(\"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/SNOMED_CT_datasets/SNOMED_International/SnomedCT_InternationalRF2/Snapshot\")\n","OUT_JSONL = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/snomed_term_definition_only.jsonl\"\n","\n","# 언어 Refset ID (US English=900000000000509007, GB English=900000000000508004)\n","REFSET_LANG_ID = \"900000000000509007\"  # 문자열로 두세요\n","\n","# 정의 결측 처리 정책: 'drop' 또는 'fallback'\n","MISSING_DEFINITION_POLICY = \"drop\"   # 'fallback' 으로 바꾸면 템플릿 채움\n","FALLBACK_TEMPLATE = \"{term}: a SNOMED CT clinical concept. No detailed text definition was found in the release.\"\n","# ====================================================\n","\n","def pick_first(paths):\n","    paths = list(paths)\n","    return paths[0] if paths else None\n","\n","def find_release_files(base: Path):\n","    # Concept\n","    concept_fp = pick_first(base.rglob(\"Terminology/sct2_Concept_Snapshot_INT_*.txt\")) \\\n","              or pick_first(base.rglob(\"**/sct2_Concept_Snapshot_INT_*.txt\"))\n","    if not concept_fp:\n","        raise FileNotFoundError(\"Concept Snapshot 파일을 찾지 못했습니다.\")\n","    print(\"[Concept]\", concept_fp)\n","\n","    m = re.search(r\"_(\\d{8})\\.txt$\", concept_fp.name)\n","    if not m:\n","        raise RuntimeError(\"Concept 파일명에서 날짜(YYYYMMDD)를 추출하지 못했습니다.\")\n","    date_str = m.group(1)\n","    print(\"[DATE]\", date_str)\n","\n","    # Description (동일 날짜 우선)\n","    desc_fp = pick_first(base.rglob(f\"Terminology/sct2_Description_Snapshot-en_INT_{date_str}.txt\")) \\\n","           or pick_first(base.rglob(f\"**/sct2_Description_Snapshot-en_INT_{date_str}.txt\")) \\\n","           or pick_first(base.rglob(\"**/sct2_Description_Snapshot-en_INT_*.txt\"))\n","    if not desc_fp:\n","        raise FileNotFoundError(\"Description Snapshot 파일을 찾지 못했습니다.\")\n","    print(\"[Description]\", desc_fp)\n","\n","    # TextDefinition (선택)\n","    textdef_fp = pick_first(base.rglob(f\"Terminology/sct2_TextDefinition_Snapshot-en_INT_{date_str}.txt\")) \\\n","              or pick_first(base.rglob(f\"**/sct2_TextDefinition_Snapshot-en_INT_{date_str}.txt\")) \\\n","              or pick_first(base.rglob(\"**/sct2_TextDefinition_Snapshot-en_INT_*.txt\"))\n","    print(\"[TextDefinition]\", textdef_fp if textdef_fp else \"없음\")\n","\n","    # Language refset (여러 개일 수 있어 패턴 넓게)\n","    lang_candidates = []\n","    for pat in [\n","        f\"Refset/Language/der2_cRefset_Language*{date_str}.txt\",\n","        f\"**/der2_cRefset_Language*{date_str}.txt\",\n","        \"Refset/Language/der2_cRefset_Language*.txt\",\n","        \"**/der2_cRefset_Language*.txt\",\n","    ]:\n","        lang_candidates += list(base.rglob(pat))\n","    lang_candidates = sorted(set(lang_candidates), key=lambda p: p.name)\n","    if not lang_candidates:\n","        raise FileNotFoundError(\"Language refset 파일을 찾지 못했습니다.\")\n","    lang_fp = lang_candidates[0]\n","    print(\"[Language(any)]\", lang_fp.parent)\n","\n","    return concept_fp, desc_fp, textdef_fp, lang_fp\n","\n","def strip_semantic_tag(t: str) -> str:\n","    # \"Neoplasm of jejunum (disorder)\" -> \"Neoplasm of jejunum\"\n","    m = re.match(r\"^(.*)\\s\\([^)]+\\)$\", t)\n","    return m.group(1) if m else t\n","\n","def main():\n","    concept_fp, desc_fp, textdef_fp, lang_fp = find_release_files(BASE)\n","\n","    dtype_common = {\"id\":\"string\",\"effectiveTime\":\"string\",\"active\":\"int8\",\"moduleId\":\"string\"}\n","\n","    # === Concepts ===\n","    concepts = pd.read_csv(\n","        concept_fp, sep=\"\\t\",\n","        dtype={**dtype_common, \"definitionStatusId\":\"string\"}\n","    )\n","    concepts = concepts.query(\"active==1\")[[\"id\"]].rename(columns={\"id\":\"conceptId\"})\n","    concepts[\"conceptId\"] = concepts[\"conceptId\"].astype(\"int64\")\n","\n","    # === Descriptions ===\n","    descs = pd.read_csv(\n","        desc_fp, sep=\"\\t\",\n","        dtype={\n","            **dtype_common,\n","            \"conceptId\":\"int64\",\n","            \"languageCode\":\"string\",\n","            \"typeId\":\"string\",\n","            \"term\":\"string\",\n","            \"caseSignificanceId\":\"string\"\n","        }\n","    ).query(\"active==1\")\n","\n","    # === Language refset ===\n","    lang_all = pd.read_csv(\n","        lang_fp, sep=\"\\t\",\n","        dtype={**dtype_common, \"refsetId\":\"string\", \"referencedComponentId\":\"string\", \"acceptabilityId\":\"string\"}\n","    ).query(\"active==1\")\n","    lang = lang_all.query(\"refsetId==@REFSET_LANG_ID\")[\n","        [\"referencedComponentId\",\"acceptabilityId\"]\n","    ].rename(columns={\"referencedComponentId\":\"descriptionId\"})\n","\n","    # === Text Definitions (optional) ===\n","    if textdef_fp:\n","        textdefs = pd.read_csv(\n","            textdef_fp, sep=\"\\t\",\n","            dtype={\n","                **dtype_common,\n","                \"conceptId\":\"int64\",\n","                \"languageCode\":\"string\",\n","                \"typeId\":\"string\",\n","                \"term\":\"string\",\n","                \"caseSignificanceId\":\"string\"\n","            }\n","        ).query(\"active==1\")\n","    else:\n","        textdefs = pd.DataFrame(columns=[\"conceptId\",\"term\",\"typeId\"])\n","\n","    # === RF2 상수 ===\n","    TYPEID_FSN       = \"900000000000003001\"\n","    TYPEID_SYNONYM   = \"900000000000013009\"\n","    TYPEID_TEXT_DEF  = \"900000000000550004\"\n","    ACC_PREFERRED    = \"900000000000548007\"\n","    ACC_ACCEPTABLE   = \"900000000000549004\"\n","\n","    # ---- Preferred term 선택 (synonym 우선, 없으면 FSN clean) ----\n","    syn = descs.query(\"typeId==@TYPEID_SYNONYM\")[[\"id\",\"conceptId\",\"term\"]].rename(columns={\"id\":\"descriptionId\"})\n","    syn = syn.merge(lang, on=\"descriptionId\", how=\"left\")\n","    syn[\"acc_score\"] = syn[\"acceptabilityId\"].map({ACC_PREFERRED:2, ACC_ACCEPTABLE:1}).fillna(0).astype(int)\n","    syn_ranked = syn.sort_values([\"conceptId\",\"acc_score\"], ascending=[True, False])\n","    preferred_syn = syn_ranked.groupby(\"conceptId\", as_index=False).first()[[\"conceptId\",\"term\"]]\n","    preferred_syn = preferred_syn.rename(columns={\"term\":\"label\"})\n","\n","    fsn = descs.query(\"typeId==@TYPEID_FSN\")[[\"conceptId\",\"term\"]].rename(columns={\"term\":\"fsn\"})\n","    fsn[\"fsn_clean\"] = fsn[\"fsn\"].map(strip_semantic_tag)\n","\n","    label_df = concepts.merge(preferred_syn, on=\"conceptId\", how=\"left\") \\\n","                       .merge(fsn[[\"conceptId\",\"fsn_clean\"]], on=\"conceptId\", how=\"left\")\n","    # 최종 term\n","    label_df[\"term\"] = label_df[\"label\"].fillna(label_df[\"fsn_clean\"]).astype(\"string\").str.strip()\n","    label_df = label_df.drop(columns=[c for c in [\"label\",\"fsn_clean\"] if c in label_df.columns])\n","\n","    # ---- definition 붙이기 ----\n","    if not textdefs.empty:\n","        defs = textdefs.query(\"typeId==@TYPEID_TEXT_DEF\")[[\"conceptId\",\"term\"]] \\\n","                       .rename(columns={\"term\":\"definition\"})\n","    else:\n","        defs = pd.DataFrame(columns=[\"conceptId\",\"definition\"])\n","\n","    pairs = label_df.merge(defs, on=\"conceptId\", how=\"left\")\n","    pairs[\"definition\"] = pairs[\"definition\"].fillna(\"\").astype(\"string\").str.strip()\n","    pairs[\"term\"] = pairs[\"term\"].fillna(\"\").astype(\"string\").str.strip()\n","\n","    # term 비어있는 것 제거\n","    pairs = pairs[pairs[\"term\"] != \"\"].copy()\n","\n","    # --- definition 결측 처리 정책 ---\n","    if MISSING_DEFINITION_POLICY == \"drop\":\n","        before = len(pairs)\n","        pairs = pairs[pairs[\"definition\"] != \"\"].copy()\n","        print(f\"[Policy=drop] 정의문 없는 {before - len(pairs)}행 제거, 남은 행: {len(pairs)}\")\n","    elif MISSING_DEFINITION_POLICY == \"fallback\":\n","        mask = pairs[\"definition\"] == \"\"\n","        n_missing = int(mask.sum())\n","        pairs.loc[mask, \"definition\"] = pairs.loc[mask, \"term\"].apply(\n","            lambda t: FALLBACK_TEMPLATE.format(term=t)\n","        )\n","        print(f\"[Policy=fallback] 정의문 없는 {n_missing}행을 템플릿으로 대체, 총 행: {len(pairs)}\")\n","    else:\n","        raise ValueError(\"MISSING_DEFINITION_POLICY must be 'drop' or 'fallback'.\")\n","\n","    # ==== JSONL 저장 (conceptId/동의어 제외) ====\n","    n_written = 0\n","    with open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n","        for _, r in pairs.iterrows():\n","            rec = {\n","                \"messages\": [\n","                    {\"role\": \"user\", \"content\": r[\"term\"]},\n","                    {\"role\": \"assistant\", \"content\": r[\"definition\"]}\n","                ]\n","            }\n","            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n","            n_written += 1\n","\n","    print(f\"Saved JSONL: {OUT_JSONL} (rows={n_written})\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OP3_cookUfy0"},"outputs":[],"source":["jsonl_path = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/snomed_term_definition_only.jsonl\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBBoJVg9VCQk"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_json(jsonl_path, lines=True)\n","\n","# 완전 텍스트 출력\n","print(df.head(10).to_string(index=False))\n"]},{"cell_type":"markdown","metadata":{"id":"A736-eGtVEpD"},"source":["# 용어 정의 제대로 하는지 검증"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-VBGvAFF52pc"},"outputs":[],"source":["# Inference: Ask the fine-tuned model to define a term\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from peft import PeftModel\n","import torch\n","\n","# ==== 경로 설정 ====\n","BASE_MODEL   = \"/content/drive/MyDrive/DILAB/qwen3-8b\"  # 베이스 모델(또는 허깅페이스 경로)\n","ADAPTER_DIR  = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Models/qwen3_8b_snomed_lora\"  # LoRA 어댑터\n","USE_4BIT     = True\n","USE_BF16     = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n","\n","# ==== 모델/토크나이저 로드 ====\n","bnb = None\n","if USE_4BIT:\n","    bnb = BitsAndBytesConfig(\n","        load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_compute_dtype=torch.bfloat16 if USE_BF16 else torch.float16\n","    )\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    BASE_MODEL,\n","    quantization_config=bnb,\n","    trust_remote_code=True,\n","    device_map=\"auto\",\n","    dtype=torch.bfloat16 if USE_BF16 else torch.float16,  # torch_dtype deprec → dtype\n",")\n","tok = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True, trust_remote_code=True)\n","if tok.pad_token is None:\n","    tok.pad_token = tok.eos_token\n","\n","# LoRA 어댑터 부착 (병합 모델이면 이 부분 건너뜀)\n","model = PeftModel.from_pretrained(model, ADAPTER_DIR)\n","model.eval()\n","\n","def define_term(term: str, max_new_tokens: int = 160, deterministic: bool = True) -> str:\n","    \"\"\"학습한 포맷 그대로: user=term → assistant=definition\"\"\"\n","    messages = [\n","        {\"role\": \"user\", \"content\": term}\n","    ]\n","    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","\n","    inputs = tok([prompt], return_tensors=\"pt\").to(model.device)\n","    with torch.no_grad():\n","        out = model.generate(\n","            **inputs,\n","            max_new_tokens=max_new_tokens,\n","            do_sample=not deterministic,   # 정의문은 보통 결정적 생성 권장\n","            temperature=0.2,\n","            top_p=0.9,\n","            eos_token_id=tok.eos_token_id,\n","        )\n","    text = tok.decode(out[0], skip_special_tokens=True)\n","    # 프롬프트 길이만큼 잘라서 assistant 응답만 반환\n","    return text[len(prompt):].strip()\n","\n","# === 사용 예시 ===\n","print(define_term(\"Asthma\"))\n","print(define_term(\"Myocardial infarction\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BM4tNUX456On"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEEdRiiVYasRS7lKsBqbOp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
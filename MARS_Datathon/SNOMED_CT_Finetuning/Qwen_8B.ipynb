{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyPe4dH7QfVfghpc/Jquqr6J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SbFt5T4bEqNZ"},"outputs":[],"source":["from google.colab import drive\n","\n","# 구글 드라이브 마운트\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# 0) 혹시 남아있는 것들 제거\n","!pip -q uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft datasets einops"],"metadata":{"id":"0JBdmdNsEww2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 1) PyTorch (CUDA 12.1 빌드로 고정)\n","!pip -q install --index-url https://download.pytorch.org/whl/cu121 torch==2.4.1 torchvision torchaudio"],"metadata":{"id":"qPqardIXE3oi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2) Triton (torch 2.4.x와 궁합)\n","!pip -q install triton==2.3.0"],"metadata":{"id":"0rC2zaW7E5IE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3) bitsandbytes (cu121 바이너리 있는 버전)\n","!pip -q install bitsandbytes==0.43.1\n"],"metadata":{"id":"zCl88e_bE7dX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4) 나머지 라이브러리\n","!pip -q install \"transformers>=4.46.1\" \"accelerate>=0.33.0\" \"peft>=0.11.1\" \"datasets>=2.20.0\" \"einops\""],"metadata":{"id":"_knX53zvE9n1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch, bitsandbytes as bnb, triton, transformers\n","print(\"torch:\", torch.__version__, \"CUDA:\", torch.version.cuda)  # ← 반드시 12.1\n","print(\"triton:\", triton.__version__)\n","print(\"bitsandbytes:\", bnb.__version__)\n","import triton.ops  # ← 에러 없으면 OK\n"],"metadata":{"id":"UjEmK98iE_JB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch, bitsandbytes as bnb\n","print(\"CUDA:\", torch.cuda.is_available(), \"| device:\", torch.cuda.get_device_name(0))\n","\n","# 간단한 4bit Linear 테스트\n","from bitsandbytes.nn import Linear4bit\n","lin = Linear4bit(1024, 1024, compute_dtype=torch.bfloat16).cuda()\n","x = torch.randn(2, 1024, device=\"cuda\")\n","y = lin(x)\n","print(\"OK: 4bit matmul ->\", y.shape)\n"],"metadata":{"id":"PxR9ARybFBNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# bnb만 올리면 됨 (재시작 권장)\n","!pip -q install --upgrade bitsandbytes==0.44.1\n"],"metadata":{"id":"91p9tGxbG-Tx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from peft import LoraConfig, get_peft_model\n","import torch\n","\n","QWEN_DIR = \"/content/drive/MyDrive/DILAB/qwen3-8b\"  # 네 경로\n","\n","bnb_cfg = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,  # A100이면 bfloat16 권장\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n",")\n","\n","tok = AutoTokenizer.from_pretrained(QWEN_DIR, use_fast=False, trust_remote_code=True)\n","\n","base = AutoModelForCausalLM.from_pretrained(\n","    QWEN_DIR,\n","    trust_remote_code=True,\n","    quantization_config=bnb_cfg,\n","    device_map=\"auto\",\n","    dtype=torch.bfloat16,            # ← torch_dtype 대신 dtype 사용\n","    attn_implementation=\"eager\",     # 문제 예방용\n","    low_cpu_mem_usage=True,\n",")\n","\n","lora_cfg = LoraConfig(\n","    r=16, lora_alpha=32, lora_dropout=0.05,\n","    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],  # 필요시 실제 모듈명으로 조정\n","    bias=\"none\", task_type=\"FEATURE_EXTRACTION\",\n",")\n","\n","model = get_peft_model(base, lora_cfg)\n","model.print_trainable_parameters()\n"],"metadata":{"id":"qBO3682cF4s2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.RF2스냅샷 읽기"],"metadata":{"id":"pbdtRYdX3S6X"}},{"cell_type":"code","source":["import duckdb, pandas as pd\n","\n","DESC_FILE   = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/SNOMED_CT_datasets/SNOMED_International_2025-10/SnomedCT_InternationalRF2_PRODUCTION_20251001T120000Z/Snapshot/Terminology/sct2_Description_Snapshot-en_INT_20251001.txt\"\n","LANGREF_FILE= \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/SNOMED_CT_datasets/SNOMED_International_2025-10/SnomedCT_InternationalRF2_PRODUCTION_20251001T120000Z/Snapshot/Refset/Language/der2_cRefset_LanguageSnapshot-en_INT_20251001.txt\"\n","\n","con = duckdb.connect()\n","\n","FSN  = 900000000000003001  # Fully Specified Name\n","SYN  = 900000000000013009  # Synonym\n","PREF = 900000000000548007  # Preferred\n","\n","# 활성 영문 Description\n","con.execute(f\"\"\"\n","  CREATE OR REPLACE TEMP VIEW d AS\n","  SELECT\n","    CAST(conceptId AS BIGINT)  AS concept_id,\n","    id                          AS description_id,\n","    languageCode                AS lang,\n","    CAST(typeId AS BIGINT)     AS type_id,\n","    term\n","  FROM read_csv_auto('{DESC_FILE}', delim='\\\\t', header=1, sample_size=-1)\n","  WHERE active='1' AND languageCode='en';\n","\"\"\")\n","\n","# 활성 Language Refset(수용도)\n","con.execute(f\"\"\"\n","  CREATE OR REPLACE TEMP VIEW l AS\n","  SELECT\n","    referencedComponentId          AS description_id,\n","    CAST(acceptabilityId AS BIGINT) AS acceptability_id\n","  FROM read_csv_auto('{LANGREF_FILE}', delim='\\\\t', header=1, sample_size=-1)\n","  WHERE active='1';\n","\"\"\")\n","\n","# 개념별 동의어 세트 만들기\n","df_en = con.execute(f\"\"\"\n","  WITH joined AS (\n","    SELECT d.concept_id, d.description_id, d.type_id, d.term, l.acceptability_id\n","    FROM d LEFT JOIN l USING(description_id)\n","  )\n","  SELECT\n","    concept_id,\n","    MAX(CASE WHEN type_id={FSN} THEN term END)                                 AS fsn,\n","    MAX(CASE WHEN type_id={SYN} AND acceptability_id={PREF} THEN term END)     AS pref_syn,\n","    LIST(DISTINCT CASE WHEN type_id={SYN} THEN term END)                        AS all_synonyms\n","  FROM joined\n","  GROUP BY concept_id\n","\"\"\").df()\n","\n","len(df_en), df_en.head(3)\n"],"metadata":{"id":"0D0U7XCzF-5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. \"같은 개념 동의어\"로 PositivePair생성"],"metadata":{"id":"Uco2ZQLZHPgJ"}},{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","# 1) ndarray → list, None/공백 제거, 중복 제거(순서 보존)\n","def to_syn_list(x):\n","    # ndarray → list\n","    if isinstance(x, np.ndarray):\n","        vals = x.tolist()\n","    elif isinstance(x, list):\n","        vals = x\n","    else:\n","        return []\n","\n","    # 문자열만 남기고 공백 제거\n","    vals = [s.strip() for s in vals if isinstance(s, str) and s and s.strip()]\n","\n","    # 중복 제거 (순서 보존)\n","    seen = set()\n","    uniq = []\n","    for s in vals:\n","        if s not in seen:\n","            seen.add(s)\n","            uniq.append(s)\n","    return uniq\n","\n","df_en[\"syn_list\"] = df_en[\"all_synonyms\"].apply(to_syn_list)\n","\n","# 2) 동의어가 2개 이상인 개념 수 확인\n","ok_mask = df_en[\"syn_list\"].apply(lambda lst: len(lst) >= 2)\n","print(\"concepts with >=2 synonyms:\", ok_mask.sum())\n","\n","# 3) pairs 생성 (개념당 최대 5쌍, 인접 페어 방식 or 셔플 방식 중 택1)\n","\n","# (A) 인접 페어 방식: [\"a\",\"b\",\"c\"] → (\"a\",\"b\"), (\"b\",\"c\"), ...\n","pairs = []\n","for syns in df_en.loc[ok_mask, \"syn_list\"]:\n","    for i in range(min(5, len(syns)-1)):\n","        a, b = syns[i], syns[i+1]\n","        if a != b:\n","            pairs.append((a, b))\n","\n","print(\"pairs:\", len(pairs), \"| example:\", pairs[:5])\n","\n","# (B) 랜덤 페어 방식(원하면 이걸로): 개념당 동의어 랜덤 셔플 후 인접 페어\n","# pairs = []\n","# for syns in df_en.loc[ok_mask, \"syn_list\"]:\n","#     random.shuffle(syns)\n","#     for i in range(min(5, len(syns)-1)):\n","#         a, b = syns[i], syns[i+1]\n","#         if a != b:\n","#             pairs.append((a, b))\n","# print(\"pairs:\", len(pairs), \"| example:\", pairs[:5])\n"],"metadata":{"id":"9ADqu0Z43dP4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. InfoNCE 학습 루프(in-batch negatives)"],"metadata":{"id":"C9iNcUqL3fu8"}},{"cell_type":"code","source":["!pip -q install tqdm\n","\n","import os, math, torch, torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from dataclasses import dataclass\n","from tqdm.auto import tqdm\n","\n","# 메모리 파편화 완화(옵션)\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n","\n","# ---- 모델 메모리 절약 설정 (네가 이미 적용한 설정과 병행)\n","from peft import prepare_model_for_kbit_training\n","model.config.output_hidden_states = True\n","model.config.use_cache = False\n","model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n","\n","# ===== 하이퍼파라미터(메모리 세이브 예시) =====\n","MAX_PAIRS   = 30000\n","MAX_LENGTH  = 64\n","BATCH_SIZE  = 8\n","EPOCHS      = 1\n","LR          = 1e-4\n","GRAD_ACCUM  = 4\n","TEMPERATURE = 0.05\n","\n","device = model.device\n","\n","class PairDataset(Dataset):\n","    def __init__(self, pairs): self.pairs = pairs\n","    def __len__(self): return len(self.pairs)\n","    def __getitem__(self, i):\n","        a, b = self.pairs[i]\n","        return {\"a\": a, \"b\": b}\n","\n","@dataclass\n","class Batch:\n","    input_ids_a: torch.Tensor\n","    attention_mask_a: torch.Tensor\n","    input_ids_b: torch.Tensor\n","    attention_mask_b: torch.Tensor\n","\n","def collate(batch):\n","    a = [b[\"a\"] for b in batch]\n","    b = [b[\"b\"] for b in batch]\n","    ta = tok(a, padding=True, truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n","    tb = tok(b, padding=True, truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n","    return Batch(ta[\"input_ids\"], ta[\"attention_mask\"], tb[\"input_ids\"], tb[\"attention_mask\"])\n","\n","def mean_pool(last_hidden_state, attention_mask):\n","    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n","    summed = (last_hidden_state * mask).sum(dim=1)\n","    denom  = mask.sum(dim=1).clamp(min=1e-6)\n","    return summed / denom\n","\n","def gpu_mem_gb():\n","    if not torch.cuda.is_available(): return \"CPU\"\n","    alloc = torch.cuda.memory_allocated() / (1024**3)\n","    reserv = torch.cuda.memory_reserved() / (1024**3)\n","    tot = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n","    return f\"alloc {alloc:.2f}G / reserved {reserv:.2f}G / total {tot:.0f}G\"\n","\n","# DataLoader/Optim\n","ds = PairDataset(pairs[:MAX_PAIRS])\n","if len(ds) == 0:\n","    raise RuntimeError(\"pairs가 0개입니다. pairs 생성 과정을 확인하세요.\")\n","\n","dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate)\n","optim = torch.optim.AdamW(model.parameters(), lr=LR)\n","\n","# ===== 학습 루프 (진행바 + EMA 손실 + 메모리 로그) =====\n","model.train()\n","ema = None\n","beta = 0.98  # EMA 계수\n","autocast_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n","\n","for epoch in range(EPOCHS):\n","    pbar = tqdm(enumerate(dl, 1), total=len(dl), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n","    optim.zero_grad(set_to_none=True)\n","\n","    for step, batch in pbar:\n","        batch = Batch(\n","            batch.input_ids_a.to(device, non_blocking=True),\n","            batch.attention_mask_a.to(device, non_blocking=True),\n","            batch.input_ids_b.to(device, non_blocking=True),\n","            batch.attention_mask_b.to(device, non_blocking=True),\n","        )\n","\n","        with torch.autocast(device_type=\"cuda\", dtype=autocast_dtype):\n","            out_a = model(\n","                input_ids=batch.input_ids_a,\n","                attention_mask=batch.attention_mask_a,\n","                output_hidden_states=True, use_cache=False, return_dict=True,\n","            )\n","            out_b = model(\n","                input_ids=batch.input_ids_b,\n","                attention_mask=batch.attention_mask_b,\n","                output_hidden_states=True, use_cache=False, return_dict=True,\n","            )\n","\n","            h_a = out_a.hidden_states[-1]\n","            h_b = out_b.hidden_states[-1]\n","\n","            emb_a = mean_pool(h_a, batch.attention_mask_a)\n","            emb_b = mean_pool(h_b, batch.attention_mask_b)\n","            emb_a = F.normalize(emb_a, p=2, dim=1)\n","            emb_b = F.normalize(emb_b, p=2, dim=1)\n","\n","            logits = (emb_a @ emb_b.T) / TEMPERATURE\n","            target = torch.arange(logits.size(0), device=device)\n","            loss = 0.5 * (F.cross_entropy(logits, target) + F.cross_entropy(logits.T, target))\n","\n","        loss.backward()\n","\n","        if step % GRAD_ACCUM == 0:\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optim.step()\n","            optim.zero_grad(set_to_none=True)\n","\n","        # EMA 업데이트 + 진행바 표시\n","        ema = loss.item() if ema is None else beta*ema + (1-beta)*loss.item()\n","        pbar.set_postfix({\n","            \"loss\": f\"{loss.item():.4f}\",\n","            \"ema\": f\"{ema:.4f}\",\n","            \"mem\": gpu_mem_gb()\n","        })\n","\n","        # 가끔 캐시 비워 파편화 완화\n","        if step % (GRAD_ACCUM*50) == 0:\n","            torch.cuda.empty_cache()\n","\n","    print(f\"[epoch {epoch+1}] EMA loss: {ema:.4f} | {gpu_mem_gb()}\")\n","\n","print(\"✅ training loop done\")\n"],"metadata":{"id":"fXdmtd093mIj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. LoRA 어댑터를 Drive에 저장&저장 되었는지 확인"],"metadata":{"id":"DD8_I1cw3usO"}},{"cell_type":"code","source":["SAVE_DIR = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Models/qwen3-8b-snomed-embed-lora\"\n","model.save_pretrained(SAVE_DIR)\n","tok.save_pretrained(SAVE_DIR)\n","print(\"saved to:\", SAVE_DIR)\n"],"metadata":{"id":"vBmsbX-J37Zp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. 유사도 확인"],"metadata":{"id":"agSd62M538ag"}},{"cell_type":"code","source":["from peft import PeftModel\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","import torch, torch.nn.functional as F\n","\n","QWEN_DIR = \"/content/drive/MyDrive/DILAB/qwen3-8b\"  # 네 베이스 모델 경로\n","LORA_DIR = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Models/qwen3-8b-snomed-embed-lora\"\n","\n","bnb_cfg = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n",")\n","\n","tok2 = AutoTokenizer.from_pretrained(QWEN_DIR, use_fast=False, trust_remote_code=True)\n","base2 = AutoModelForCausalLM.from_pretrained(\n","    QWEN_DIR,\n","    trust_remote_code=True,\n","    quantization_config=bnb_cfg,\n","    dtype=torch.bfloat16,\n","    device_map=\"auto\",\n","    attn_implementation=\"eager\",\n",")\n","mdl2 = PeftModel.from_pretrained(base2, LORA_DIR)\n","\n","# 추론에서도 히든스테이트를 뽑도록 설정\n","mdl2.config.output_hidden_states = True\n","mdl2.config.use_cache = False\n","mdl2.eval()\n","\n","def mean_pool(hidden, mask):\n","    mask = mask.unsqueeze(-1).type_as(hidden)\n","    summed = (hidden * mask).sum(dim=1)\n","    denom  = mask.sum(dim=1).clamp(min=1e-6)\n","    return summed / denom\n","\n","@torch.no_grad()\n","def encode(texts, max_length=96):\n","    b = tok2(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(mdl2.device)\n","    o = mdl2(**b, output_hidden_states=True, use_cache=False, return_dict=True)\n","    h = o.hidden_states[-1]                 # ✅ 마지막 레이어 히든스테이트 사용\n","    e = mean_pool(h, b[\"attention_mask\"])\n","    return F.normalize(e, p=2, dim=1).cpu()\n","\n","# 간단 유사도 테스트\n","cands = [\"liver cirrhosis\", \"hepatic cirrhosis\", \"chronic obstructive pulmonary disease\", \"hepatitis C\"]\n","q = \"hepatic cirrhosis\"\n","qe = encode([q]); ce = encode(cands)\n","sims = (qe @ ce.T)[0].tolist()\n","for c, s in sorted(zip(cands, sims), key=lambda x: -x[1]):\n","    print(f\"{c:<45s} {s:.3f}\")\n"],"metadata":{"id":"YJ6Yhm6T3_0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cands = [\n","    \"liver cirrhosis\",                     # 진짜 동의어\n","    \"hepatitis C\",                         # 관련은 있지만 다른 질환\n","    \"chronic obstructive pulmonary disease\",  # 다른 장기\n","    \"banana\", \"quantum entanglement\", \"table tennis\", \"K-pop idol\"  # 무관\n","]\n","q = \"hepatic cirrhosis\"\n","qe = encode([q]); ce = encode(cands)\n","sims = (qe @ ce.T)[0].tolist()\n","for c, s in sorted(zip(cands, sims), key=lambda x: -x[1]):\n","    print(f\"{c:<35s} {s:.3f}\")\n"],"metadata":{"id":"GTBO4iwU4Afb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xbbnM66FUlq0"},"execution_count":null,"outputs":[]}]}
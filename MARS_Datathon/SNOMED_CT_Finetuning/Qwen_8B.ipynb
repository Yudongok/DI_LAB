{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyPe4dH7QfVfghpc/Jquqr6J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cb3bfe7461ce4dc3af58ea5db0d80c76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4eef9785fcb64622b6f0fe43a0ffedb6","IPY_MODEL_4393b812323c4a76b0b5e87374bbacbb","IPY_MODEL_0679121afc6240d99d896601a3f26782"],"layout":"IPY_MODEL_177213c433694857a6a5229864c6eafc"}},"4eef9785fcb64622b6f0fe43a0ffedb6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_497aba14ce5744d987e3074aedb11fb1","placeholder":"​","style":"IPY_MODEL_9fb42e79ec7b46b3bf1c1bd0e1477801","value":"Loading checkpoint shards: 100%"}},"4393b812323c4a76b0b5e87374bbacbb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c4ce0038ef8426f9167677c9b718d34","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3fc473cdf9ba4d4e89eabcf24eca6bf6","value":5}},"0679121afc6240d99d896601a3f26782":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_feefdfbf7b644830b619e3af01aa1701","placeholder":"​","style":"IPY_MODEL_aad8adaa28cb44019788620674fc2448","value":" 5/5 [03:49&lt;00:00, 40.09s/it]"}},"177213c433694857a6a5229864c6eafc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"497aba14ce5744d987e3074aedb11fb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fb42e79ec7b46b3bf1c1bd0e1477801":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c4ce0038ef8426f9167677c9b718d34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc473cdf9ba4d4e89eabcf24eca6bf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"feefdfbf7b644830b619e3af01aa1701":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad8adaa28cb44019788620674fc2448":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"933e850a19ba43f8b58a3085759ae269":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7e02fcd42854ae89ed9da004247fd8c","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bef7c06f9ac1444b9d7dd77c210d9eeb","value":100}},"a7e02fcd42854ae89ed9da004247fd8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"auto"}},"bef7c06f9ac1444b9d7dd77c210d9eeb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":"black","description_width":""}},"d6d466b337df4a809453869a8107db33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e63ea643700440eaca80e34a2ae95b2","IPY_MODEL_59006f16391249e8ab92c9b4c32631dc","IPY_MODEL_4a6e631e67614368aa7cccdf48053539"],"layout":"IPY_MODEL_71e6568fcf914cba999ec519349c0226"}},"0e63ea643700440eaca80e34a2ae95b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e692d8cb38ce41d898ab1963bdfc082c","placeholder":"​","style":"IPY_MODEL_efd25bd99adc4f5aa0199360cfd1069f","value":"Epoch 1/1: 100%"}},"59006f16391249e8ab92c9b4c32631dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0bf0ea0c164406c874c0c265267b30b","max":3750,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07925d0f6c7e48cca14e4527ca54491b","value":3750}},"4a6e631e67614368aa7cccdf48053539":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03127ccdc39b44d1a6a781e0eeb6e3b6","placeholder":"​","style":"IPY_MODEL_596fd6f4b9f14ec39e3f8da0a38615de","value":" 3750/3750 [1:05:10&lt;00:00,  1.04s/it, loss=0.9885, ema=1.2250, mem=alloc 10.57G / reserved 12.76G / total 79G]"}},"71e6568fcf914cba999ec519349c0226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e692d8cb38ce41d898ab1963bdfc082c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efd25bd99adc4f5aa0199360cfd1069f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0bf0ea0c164406c874c0c265267b30b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07925d0f6c7e48cca14e4527ca54491b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03127ccdc39b44d1a6a781e0eeb6e3b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"596fd6f4b9f14ec39e3f8da0a38615de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"374c96c632a44caab32a49f63de0e4e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8384aba333b94e5e8e867fca0f2f8542","IPY_MODEL_f77f4e5db4c34ba4ba5e6c6030857392","IPY_MODEL_ec5e76bffd5f4b9abe568893d65c1d33"],"layout":"IPY_MODEL_f271b364b9ea4544a189ac9859cccd40"}},"8384aba333b94e5e8e867fca0f2f8542":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3b268e87de74e7fb59066927e3cec7d","placeholder":"​","style":"IPY_MODEL_74652b48209a4303a117f56de29983c7","value":"Loading checkpoint shards: 100%"}},"f77f4e5db4c34ba4ba5e6c6030857392":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_049c70409a3d4e4f9bbfc382dacf0a53","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_953cd097be644d4d94df3c229b05263a","value":5}},"ec5e76bffd5f4b9abe568893d65c1d33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98d9610e532545689356a59dd01411c3","placeholder":"​","style":"IPY_MODEL_40cb49a5a12d48739e67885a5ff451ed","value":" 5/5 [00:25&lt;00:00,  4.20s/it]"}},"f271b364b9ea4544a189ac9859cccd40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3b268e87de74e7fb59066927e3cec7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74652b48209a4303a117f56de29983c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"049c70409a3d4e4f9bbfc382dacf0a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"953cd097be644d4d94df3c229b05263a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98d9610e532545689356a59dd01411c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40cb49a5a12d48739e67885a5ff451ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbFt5T4bEqNZ","executionInfo":{"status":"ok","timestamp":1759660796939,"user_tz":-540,"elapsed":21655,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"bbfc943b-76d0-4cc3-9d03-09a83c4adc35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# 구글 드라이브 마운트\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# 0) 혹시 남아있는 것들 제거\n","!pip -q uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft datasets einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JBdmdNsEww2","executionInfo":{"status":"ok","timestamp":1759660816959,"user_tz":-540,"elapsed":20017,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"4bccbc11-3c76-402f-e735-06dd530ef879"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["\n","# 1) PyTorch (CUDA 12.1 빌드로 고정)\n","!pip -q install --index-url https://download.pytorch.org/whl/cu121 torch==2.4.1 torchvision torchaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPqardIXE3oi","executionInfo":{"status":"ok","timestamp":1759660935678,"user_tz":-540,"elapsed":118704,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"84397ec8-3a03-4591-bca7-2a3089615304"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m139.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# 2) Triton (torch 2.4.x와 궁합)\n","!pip -q install triton==2.3.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rC2zaW7E5IE","executionInfo":{"status":"ok","timestamp":1759660943901,"user_tz":-540,"elapsed":8219,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"bde8fff9-5942-4963-ca81-711317ec02fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, which is not installed.\n","torch 2.4.1+cu121 requires triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\", but you have triton 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# 3) bitsandbytes (cu121 바이너리 있는 버전)\n","!pip -q install bitsandbytes==0.43.1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zCl88e_bE7dX","executionInfo":{"status":"ok","timestamp":1759660959397,"user_tz":-540,"elapsed":15481,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"db128bac-9924-4305-bdc9-80f53d2aab11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# 4) 나머지 라이브러리\n","!pip -q install \"transformers>=4.46.1\" \"accelerate>=0.33.0\" \"peft>=0.11.1\" \"datasets>=2.20.0\" \"einops\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_knX53zvE9n1","executionInfo":{"status":"ok","timestamp":1759660977813,"user_tz":-540,"elapsed":18417,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"ad834624-455c-448c-a981-23640161b670"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n","pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import torch, bitsandbytes as bnb, triton, transformers\n","print(\"torch:\", torch.__version__, \"CUDA:\", torch.version.cuda)  # ← 반드시 12.1\n","print(\"triton:\", triton.__version__)\n","print(\"bitsandbytes:\", bnb.__version__)\n","import triton.ops  # ← 에러 없으면 OK\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjEmK98iE_JB","executionInfo":{"status":"ok","timestamp":1759660980882,"user_tz":-540,"elapsed":3057,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"1057ee53-c5c4-4e77-8de9-6ad80c8d71e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch: 2.4.1+cu121 CUDA: 12.1\n","triton: 3.0.0\n","bitsandbytes: 0.43.1\n"]}]},{"cell_type":"code","source":["import torch, bitsandbytes as bnb\n","print(\"CUDA:\", torch.cuda.is_available(), \"| device:\", torch.cuda.get_device_name(0))\n","\n","# 간단한 4bit Linear 테스트\n","from bitsandbytes.nn import Linear4bit\n","lin = Linear4bit(1024, 1024, compute_dtype=torch.bfloat16).cuda()\n","x = torch.randn(2, 1024, device=\"cuda\")\n","y = lin(x)\n","print(\"OK: 4bit matmul ->\", y.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxR9ARybFBNp","executionInfo":{"status":"ok","timestamp":1759660981117,"user_tz":-540,"elapsed":234,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"28dc29ed-5125-4261-e217-ce7f8c23d167"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA: True | device: NVIDIA A100-SXM4-80GB\n","OK: 4bit matmul -> torch.Size([2, 1024])\n"]}]},{"cell_type":"code","source":["# bnb만 올리면 됨 (재시작 권장)\n","!pip -q install --upgrade bitsandbytes==0.44.1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"91p9tGxbG-Tx","executionInfo":{"status":"ok","timestamp":1759660988392,"user_tz":-540,"elapsed":7266,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"5fa6d7ca-7ba0-4dad-f0e6-a4fe7930660e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from peft import LoraConfig, get_peft_model\n","import torch\n","\n","QWEN_DIR = \"/content/drive/MyDrive/DILAB/qwen3-8b\"  # 네 경로\n","\n","bnb_cfg = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,  # A100이면 bfloat16 권장\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n",")\n","\n","tok = AutoTokenizer.from_pretrained(QWEN_DIR, use_fast=False, trust_remote_code=True)\n","\n","base = AutoModelForCausalLM.from_pretrained(\n","    QWEN_DIR,\n","    trust_remote_code=True,\n","    quantization_config=bnb_cfg,\n","    device_map=\"auto\",\n","    dtype=torch.bfloat16,            # ← torch_dtype 대신 dtype 사용\n","    attn_implementation=\"eager\",     # 문제 예방용\n","    low_cpu_mem_usage=True,\n",")\n","\n","lora_cfg = LoraConfig(\n","    r=16, lora_alpha=32, lora_dropout=0.05,\n","    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],  # 필요시 실제 모듈명으로 조정\n","    bias=\"none\", task_type=\"FEATURE_EXTRACTION\",\n",")\n","\n","model = get_peft_model(base, lora_cfg)\n","model.print_trainable_parameters()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["cb3bfe7461ce4dc3af58ea5db0d80c76","4eef9785fcb64622b6f0fe43a0ffedb6","4393b812323c4a76b0b5e87374bbacbb","0679121afc6240d99d896601a3f26782","177213c433694857a6a5229864c6eafc","497aba14ce5744d987e3074aedb11fb1","9fb42e79ec7b46b3bf1c1bd0e1477801","1c4ce0038ef8426f9167677c9b718d34","3fc473cdf9ba4d4e89eabcf24eca6bf6","feefdfbf7b644830b619e3af01aa1701","aad8adaa28cb44019788620674fc2448"]},"id":"qBO3682cF4s2","executionInfo":{"status":"ok","timestamp":1759661232642,"user_tz":-540,"elapsed":244251,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"64d43387-840e-4d81-935d-15a22540e16f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb3bfe7461ce4dc3af58ea5db0d80c76"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["trainable params: 15,335,424 || all params: 8,206,070,784 || trainable%: 0.1869\n"]}]},{"cell_type":"markdown","source":["### 1.RF2스냅샷 읽기"],"metadata":{"id":"pbdtRYdX3S6X"}},{"cell_type":"code","source":["import duckdb, pandas as pd\n","\n","DESC_FILE   = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/SNOMED_CT_datasets/SNOMED_International_2025-10/SnomedCT_InternationalRF2_PRODUCTION_20251001T120000Z/Snapshot/Terminology/sct2_Description_Snapshot-en_INT_20251001.txt\"\n","LANGREF_FILE= \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Datasets/SNOMED_CT_datasets/SNOMED_International_2025-10/SnomedCT_InternationalRF2_PRODUCTION_20251001T120000Z/Snapshot/Refset/Language/der2_cRefset_LanguageSnapshot-en_INT_20251001.txt\"\n","\n","con = duckdb.connect()\n","\n","FSN  = 900000000000003001  # Fully Specified Name\n","SYN  = 900000000000013009  # Synonym\n","PREF = 900000000000548007  # Preferred\n","\n","# 활성 영문 Description\n","con.execute(f\"\"\"\n","  CREATE OR REPLACE TEMP VIEW d AS\n","  SELECT\n","    CAST(conceptId AS BIGINT)  AS concept_id,\n","    id                          AS description_id,\n","    languageCode                AS lang,\n","    CAST(typeId AS BIGINT)     AS type_id,\n","    term\n","  FROM read_csv_auto('{DESC_FILE}', delim='\\\\t', header=1, sample_size=-1)\n","  WHERE active='1' AND languageCode='en';\n","\"\"\")\n","\n","# 활성 Language Refset(수용도)\n","con.execute(f\"\"\"\n","  CREATE OR REPLACE TEMP VIEW l AS\n","  SELECT\n","    referencedComponentId          AS description_id,\n","    CAST(acceptabilityId AS BIGINT) AS acceptability_id\n","  FROM read_csv_auto('{LANGREF_FILE}', delim='\\\\t', header=1, sample_size=-1)\n","  WHERE active='1';\n","\"\"\")\n","\n","# 개념별 동의어 세트 만들기\n","df_en = con.execute(f\"\"\"\n","  WITH joined AS (\n","    SELECT d.concept_id, d.description_id, d.type_id, d.term, l.acceptability_id\n","    FROM d LEFT JOIN l USING(description_id)\n","  )\n","  SELECT\n","    concept_id,\n","    MAX(CASE WHEN type_id={FSN} THEN term END)                                 AS fsn,\n","    MAX(CASE WHEN type_id={SYN} AND acceptability_id={PREF} THEN term END)     AS pref_syn,\n","    LIST(DISTINCT CASE WHEN type_id={SYN} THEN term END)                        AS all_synonyms\n","  FROM joined\n","  GROUP BY concept_id\n","\"\"\").df()\n","\n","len(df_en), df_en.head(3)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324,"referenced_widgets":["933e850a19ba43f8b58a3085759ae269","a7e02fcd42854ae89ed9da004247fd8c","bef7c06f9ac1444b9d7dd77c210d9eeb"]},"id":"0D0U7XCzF-5t","executionInfo":{"status":"ok","timestamp":1759661262295,"user_tz":-540,"elapsed":29635,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"c086a372-e091-464b-e329-76cb51feaf08"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"933e850a19ba43f8b58a3085759ae269"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["(526490,\n","    concept_id                                      fsn  \\\n"," 0   112239003  By inhalation (route) (qualifier value)   \n"," 1   428863007  History of vitreous floater (situation)   \n"," 2   403580009            Religious stigmata (disorder)   \n"," \n","                       pref_syn  \\\n"," 0                By inhalation   \n"," 1  History of vitreous floater   \n"," 2           Religious stigmata   \n"," \n","                                         all_synonyms  \n"," 0  [By inhalation, None, By inhalation (route), R...  \n"," 1                [None, History of vitreous floater]  \n"," 2                         [None, Religious stigmata]  )"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### 2. \"같은 개념 동의어\"로 PositivePair생성"],"metadata":{"id":"Uco2ZQLZHPgJ"}},{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","# 1) ndarray → list, None/공백 제거, 중복 제거(순서 보존)\n","def to_syn_list(x):\n","    # ndarray → list\n","    if isinstance(x, np.ndarray):\n","        vals = x.tolist()\n","    elif isinstance(x, list):\n","        vals = x\n","    else:\n","        return []\n","\n","    # 문자열만 남기고 공백 제거\n","    vals = [s.strip() for s in vals if isinstance(s, str) and s and s.strip()]\n","\n","    # 중복 제거 (순서 보존)\n","    seen = set()\n","    uniq = []\n","    for s in vals:\n","        if s not in seen:\n","            seen.add(s)\n","            uniq.append(s)\n","    return uniq\n","\n","df_en[\"syn_list\"] = df_en[\"all_synonyms\"].apply(to_syn_list)\n","\n","# 2) 동의어가 2개 이상인 개념 수 확인\n","ok_mask = df_en[\"syn_list\"].apply(lambda lst: len(lst) >= 2)\n","print(\"concepts with >=2 synonyms:\", ok_mask.sum())\n","\n","# 3) pairs 생성 (개념당 최대 5쌍, 인접 페어 방식 or 셔플 방식 중 택1)\n","\n","# (A) 인접 페어 방식: [\"a\",\"b\",\"c\"] → (\"a\",\"b\"), (\"b\",\"c\"), ...\n","pairs = []\n","for syns in df_en.loc[ok_mask, \"syn_list\"]:\n","    for i in range(min(5, len(syns)-1)):\n","        a, b = syns[i], syns[i+1]\n","        if a != b:\n","            pairs.append((a, b))\n","\n","print(\"pairs:\", len(pairs), \"| example:\", pairs[:5])\n","\n","# (B) 랜덤 페어 방식(원하면 이걸로): 개념당 동의어 랜덤 셔플 후 인접 페어\n","# pairs = []\n","# for syns in df_en.loc[ok_mask, \"syn_list\"]:\n","#     random.shuffle(syns)\n","#     for i in range(min(5, len(syns)-1)):\n","#         a, b = syns[i], syns[i+1]\n","#         if a != b:\n","#             pairs.append((a, b))\n","# print(\"pairs:\", len(pairs), \"| example:\", pairs[:5])\n"],"metadata":{"id":"9ADqu0Z43dP4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759661264286,"user_tz":-540,"elapsed":1798,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"5a346953-b032-4de5-f0eb-3116fb515327"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["concepts with >=2 synonyms: 202235\n","pairs: 317738 | example: [('By inhalation', 'By inhalation (route)'), ('By inhalation (route)', 'Respiratory use'), ('Entire superior rectal nerve plexus', 'Entire superior rectal plexus'), ('History of two abortions', 'H/O: 2 abortions'), ('Theatre', 'Theater')]\n"]}]},{"cell_type":"markdown","source":["### 4. InfoNCE 학습 루프(in-batch negatives)"],"metadata":{"id":"C9iNcUqL3fu8"}},{"cell_type":"code","source":["!pip -q install tqdm\n","\n","import os, math, torch, torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from dataclasses import dataclass\n","from tqdm.auto import tqdm\n","\n","# 메모리 파편화 완화(옵션)\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n","\n","# ---- 모델 메모리 절약 설정 (네가 이미 적용한 설정과 병행)\n","from peft import prepare_model_for_kbit_training\n","model.config.output_hidden_states = True\n","model.config.use_cache = False\n","model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n","\n","# ===== 하이퍼파라미터(메모리 세이브 예시) =====\n","MAX_PAIRS   = 30000\n","MAX_LENGTH  = 64\n","BATCH_SIZE  = 8\n","EPOCHS      = 1\n","LR          = 1e-4\n","GRAD_ACCUM  = 4\n","TEMPERATURE = 0.05\n","\n","device = model.device\n","\n","class PairDataset(Dataset):\n","    def __init__(self, pairs): self.pairs = pairs\n","    def __len__(self): return len(self.pairs)\n","    def __getitem__(self, i):\n","        a, b = self.pairs[i]\n","        return {\"a\": a, \"b\": b}\n","\n","@dataclass\n","class Batch:\n","    input_ids_a: torch.Tensor\n","    attention_mask_a: torch.Tensor\n","    input_ids_b: torch.Tensor\n","    attention_mask_b: torch.Tensor\n","\n","def collate(batch):\n","    a = [b[\"a\"] for b in batch]\n","    b = [b[\"b\"] for b in batch]\n","    ta = tok(a, padding=True, truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n","    tb = tok(b, padding=True, truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n","    return Batch(ta[\"input_ids\"], ta[\"attention_mask\"], tb[\"input_ids\"], tb[\"attention_mask\"])\n","\n","def mean_pool(last_hidden_state, attention_mask):\n","    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n","    summed = (last_hidden_state * mask).sum(dim=1)\n","    denom  = mask.sum(dim=1).clamp(min=1e-6)\n","    return summed / denom\n","\n","def gpu_mem_gb():\n","    if not torch.cuda.is_available(): return \"CPU\"\n","    alloc = torch.cuda.memory_allocated() / (1024**3)\n","    reserv = torch.cuda.memory_reserved() / (1024**3)\n","    tot = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n","    return f\"alloc {alloc:.2f}G / reserved {reserv:.2f}G / total {tot:.0f}G\"\n","\n","# DataLoader/Optim\n","ds = PairDataset(pairs[:MAX_PAIRS])\n","if len(ds) == 0:\n","    raise RuntimeError(\"pairs가 0개입니다. pairs 생성 과정을 확인하세요.\")\n","\n","dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate)\n","optim = torch.optim.AdamW(model.parameters(), lr=LR)\n","\n","# ===== 학습 루프 (진행바 + EMA 손실 + 메모리 로그) =====\n","model.train()\n","ema = None\n","beta = 0.98  # EMA 계수\n","autocast_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n","\n","for epoch in range(EPOCHS):\n","    pbar = tqdm(enumerate(dl, 1), total=len(dl), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n","    optim.zero_grad(set_to_none=True)\n","\n","    for step, batch in pbar:\n","        batch = Batch(\n","            batch.input_ids_a.to(device, non_blocking=True),\n","            batch.attention_mask_a.to(device, non_blocking=True),\n","            batch.input_ids_b.to(device, non_blocking=True),\n","            batch.attention_mask_b.to(device, non_blocking=True),\n","        )\n","\n","        with torch.autocast(device_type=\"cuda\", dtype=autocast_dtype):\n","            out_a = model(\n","                input_ids=batch.input_ids_a,\n","                attention_mask=batch.attention_mask_a,\n","                output_hidden_states=True, use_cache=False, return_dict=True,\n","            )\n","            out_b = model(\n","                input_ids=batch.input_ids_b,\n","                attention_mask=batch.attention_mask_b,\n","                output_hidden_states=True, use_cache=False, return_dict=True,\n","            )\n","\n","            h_a = out_a.hidden_states[-1]\n","            h_b = out_b.hidden_states[-1]\n","\n","            emb_a = mean_pool(h_a, batch.attention_mask_a)\n","            emb_b = mean_pool(h_b, batch.attention_mask_b)\n","            emb_a = F.normalize(emb_a, p=2, dim=1)\n","            emb_b = F.normalize(emb_b, p=2, dim=1)\n","\n","            logits = (emb_a @ emb_b.T) / TEMPERATURE\n","            target = torch.arange(logits.size(0), device=device)\n","            loss = 0.5 * (F.cross_entropy(logits, target) + F.cross_entropy(logits.T, target))\n","\n","        loss.backward()\n","\n","        if step % GRAD_ACCUM == 0:\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optim.step()\n","            optim.zero_grad(set_to_none=True)\n","\n","        # EMA 업데이트 + 진행바 표시\n","        ema = loss.item() if ema is None else beta*ema + (1-beta)*loss.item()\n","        pbar.set_postfix({\n","            \"loss\": f\"{loss.item():.4f}\",\n","            \"ema\": f\"{ema:.4f}\",\n","            \"mem\": gpu_mem_gb()\n","        })\n","\n","        # 가끔 캐시 비워 파편화 완화\n","        if step % (GRAD_ACCUM*50) == 0:\n","            torch.cuda.empty_cache()\n","\n","    print(f\"[epoch {epoch+1}] EMA loss: {ema:.4f} | {gpu_mem_gb()}\")\n","\n","print(\"✅ training loop done\")\n"],"metadata":{"id":"fXdmtd093mIj","colab":{"base_uri":"https://localhost:8080/","height":179,"referenced_widgets":["d6d466b337df4a809453869a8107db33","0e63ea643700440eaca80e34a2ae95b2","59006f16391249e8ab92c9b4c32631dc","4a6e631e67614368aa7cccdf48053539","71e6568fcf914cba999ec519349c0226","e692d8cb38ce41d898ab1963bdfc082c","efd25bd99adc4f5aa0199360cfd1069f","b0bf0ea0c164406c874c0c265267b30b","07925d0f6c7e48cca14e4527ca54491b","03127ccdc39b44d1a6a781e0eeb6e3b6","596fd6f4b9f14ec39e3f8da0a38615de"]},"executionInfo":{"status":"ok","timestamp":1759665177555,"user_tz":-540,"elapsed":3913241,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"1de9c9d7-a96e-4b5d-e303-220e5895f650"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Epoch 1/1:   0%|          | 0/3750 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d466b337df4a809453869a8107db33"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["[epoch 1] EMA loss: 1.2250 | alloc 10.57G / reserved 12.76G / total 79G\n","✅ training loop done\n"]}]},{"cell_type":"markdown","source":["### 5. LoRA 어댑터를 Drive에 저장&저장 되었는지 확인"],"metadata":{"id":"DD8_I1cw3usO"}},{"cell_type":"code","source":["SAVE_DIR = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Models/qwen3-8b-snomed-embed-lora\"\n","model.save_pretrained(SAVE_DIR)\n","tok.save_pretrained(SAVE_DIR)\n","print(\"saved to:\", SAVE_DIR)\n"],"metadata":{"id":"vBmsbX-J37Zp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759665178351,"user_tz":-540,"elapsed":775,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"c53847e2-2080-4b5d-f8dd-fd2601199b18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["saved to: /content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Models/qwen3-8b-snomed-embed-lora\n"]}]},{"cell_type":"markdown","source":["### 6. 유사도 확인"],"metadata":{"id":"agSd62M538ag"}},{"cell_type":"code","source":["from peft import PeftModel\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","import torch, torch.nn.functional as F\n","\n","QWEN_DIR = \"/content/drive/MyDrive/DILAB/qwen3-8b\"  # 네 베이스 모델 경로\n","LORA_DIR = \"/content/drive/MyDrive/DILAB/OK/DI_LAB/MARS_Datathon/Models/qwen3-8b-snomed-embed-lora\"\n","\n","bnb_cfg = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n",")\n","\n","tok2 = AutoTokenizer.from_pretrained(QWEN_DIR, use_fast=False, trust_remote_code=True)\n","base2 = AutoModelForCausalLM.from_pretrained(\n","    QWEN_DIR,\n","    trust_remote_code=True,\n","    quantization_config=bnb_cfg,\n","    dtype=torch.bfloat16,\n","    device_map=\"auto\",\n","    attn_implementation=\"eager\",\n",")\n","mdl2 = PeftModel.from_pretrained(base2, LORA_DIR)\n","\n","# 추론에서도 히든스테이트를 뽑도록 설정\n","mdl2.config.output_hidden_states = True\n","mdl2.config.use_cache = False\n","mdl2.eval()\n","\n","def mean_pool(hidden, mask):\n","    mask = mask.unsqueeze(-1).type_as(hidden)\n","    summed = (hidden * mask).sum(dim=1)\n","    denom  = mask.sum(dim=1).clamp(min=1e-6)\n","    return summed / denom\n","\n","@torch.no_grad()\n","def encode(texts, max_length=96):\n","    b = tok2(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(mdl2.device)\n","    o = mdl2(**b, output_hidden_states=True, use_cache=False, return_dict=True)\n","    h = o.hidden_states[-1]                 # ✅ 마지막 레이어 히든스테이트 사용\n","    e = mean_pool(h, b[\"attention_mask\"])\n","    return F.normalize(e, p=2, dim=1).cpu()\n","\n","# 간단 유사도 테스트\n","cands = [\"liver cirrhosis\", \"hepatic cirrhosis\", \"chronic obstructive pulmonary disease\", \"hepatitis C\"]\n","q = \"hepatic cirrhosis\"\n","qe = encode([q]); ce = encode(cands)\n","sims = (qe @ ce.T)[0].tolist()\n","for c, s in sorted(zip(cands, sims), key=lambda x: -x[1]):\n","    print(f\"{c:<45s} {s:.3f}\")\n"],"metadata":{"id":"YJ6Yhm6T3_0E","colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["374c96c632a44caab32a49f63de0e4e0","8384aba333b94e5e8e867fca0f2f8542","f77f4e5db4c34ba4ba5e6c6030857392","ec5e76bffd5f4b9abe568893d65c1d33","f271b364b9ea4544a189ac9859cccd40","f3b268e87de74e7fb59066927e3cec7d","74652b48209a4303a117f56de29983c7","049c70409a3d4e4f9bbfc382dacf0a53","953cd097be644d4d94df3c229b05263a","98d9610e532545689356a59dd01411c3","40cb49a5a12d48739e67885a5ff451ed"]},"executionInfo":{"status":"ok","timestamp":1759666146773,"user_tz":-540,"elapsed":26802,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"91e8aeeb-fcbf-48e0-c88a-5c65b1b7b1f0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374c96c632a44caab32a49f63de0e4e0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["hepatic cirrhosis                             1.000\n","liver cirrhosis                               0.977\n","hepatitis C                                   0.969\n","chronic obstructive pulmonary disease         0.949\n"]}]},{"cell_type":"code","source":["cands = [\n","    \"liver cirrhosis\",                     # 진짜 동의어\n","    \"hepatitis C\",                         # 관련은 있지만 다른 질환\n","    \"chronic obstructive pulmonary disease\",  # 다른 장기\n","    \"banana\", \"quantum entanglement\", \"table tennis\", \"K-pop idol\"  # 무관\n","]\n","q = \"hepatic cirrhosis\"\n","qe = encode([q]); ce = encode(cands)\n","sims = (qe @ ce.T)[0].tolist()\n","for c, s in sorted(zip(cands, sims), key=lambda x: -x[1]):\n","    print(f\"{c:<35s} {s:.3f}\")\n"],"metadata":{"id":"GTBO4iwU4Afb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759666920771,"user_tz":-540,"elapsed":331,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"a35b7060-e2eb-4793-a3b7-9de78fe5dae7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["liver cirrhosis                     0.980\n","hepatitis C                         0.969\n","chronic obstructive pulmonary disease 0.953\n","table tennis                        0.930\n","quantum entanglement                0.926\n","K-pop idol                          0.895\n","banana                              0.770\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xbbnM66FUlq0"},"execution_count":null,"outputs":[]}]}
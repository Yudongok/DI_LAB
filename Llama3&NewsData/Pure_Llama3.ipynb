{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNr56bUgE/2b5BC9cz24p2B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -q transformers accelerate"],"metadata":{"id":"u6yKzSJ7BBmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"C2ciTEKqD8la"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oFFdd1OB_xIu"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","import textwrap\n","\n","# 지정한 경로 가져옴\n","model_path = \"/content/drive/MyDrive/DILAB/llama3-8b\"\n","\n","# 지정한 경로에서 토크나이저, Model들을 불러온다\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_path,\n","    device_map = \"auto\", # GPU 자동 할당\n","    torch_dtype = \"auto\" # fp16 등 자동 감지\n",")\n","\n","# 파이프라인 생성\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    device_map=\"auto\",     # GPU 할당\n",")\n","\n","# 테스트 프롬프트\n","# <<Prompt Formatting>>\n","  # 방법 1.\n","# prompt = \"[INST] 삼성전자 신입사원 채용 우대조건은? \\n[/INST]\"\n","\n","  # 방법 2.\n","messages = [{\"role\":\"user\", \"content\":\"삼성전자 백엔드 파트 채용 우대사항은?\"}]\n","prompt = tokenizer.apply_chat_template(\n","    messages,\n","\t  tokenize=False,\n","\t  add_generation_prompt=True # assistant의 답변 시작 위치까지 생성\n",")\n","\n","# 텍스트 생성\n","output = pipe(\n","    prompt,\n","    max_new_tokens=500,     # 생성할 최대 토큰 수\n","    do_sample=True,        # 샘플링 방식 사용 (더 자연스럽게)\n","    temperature=0.7,       # 창의성 조절 (낮을수록 보수적)\n","    top_p=0.9,              # nucleus sampling\n","    eos_token_id=tokenizer.eos_token_id  # 문장이 끝났음을 뜻하는 eos_token_id를 명시하여, 모델이 끝을 알게 하기\n",")\n","\n","# 출력 결과 확인\n","output_text = output[0][\"generated_text\"]\n","\n","wrapped_text = textwrap.fill(output_text, width=70)\n","\n","print(wrapped_text)\n","\n"]},{"cell_type":"code","source":["import os\n","print(\"현재 작업 디렉토리:\", os.getcwd())\n"],"metadata":{"id":"gIRaCKJAAFiU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"5RaDCBfoC5HD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T259b8v9I5Aj"},"execution_count":null,"outputs":[]}]}